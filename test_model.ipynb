{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dc6f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Tokenizer import Tokenizer\n",
    "from data_module import DataModule\n",
    "from Model import Transformer_LM\n",
    "import torch\n",
    "\n",
    "class Configs:\n",
    "    def __init__(self):\n",
    "        self.manifest_file = \"total_am.txt\"\n",
    "        self.labels_path = \"aihub_labels.csv\"\n",
    "        self.train_ratio = 0.8\n",
    "        self.num_workers = 4\n",
    "        self.batch_size = 64\n",
    "        self.sample_mode = 'random' #'smart'\n",
    "        self.teacher_forcing_ratio = 0.0\n",
    "        \n",
    "        self.num_classes = 2001\n",
    "        self.d_model = 512\n",
    "        self.d_ff = 2048\n",
    "        self.num_heads = 4\n",
    "        self.num_layers = 3\n",
    "        self.model_name = \"BERT\"\n",
    "        \n",
    "configs = Configs()\n",
    "tokenizer = Tokenizer(label_file=configs.labels_path)\n",
    "tokenizer.idx2char[2000] = \"<mask>\"\n",
    "model = Transformer_LM(\n",
    "    num_classes=configs.num_classes,\n",
    "    d_model=configs.d_model,\n",
    "    d_ff=configs.d_ff,\n",
    "    num_heads=configs.num_heads,\n",
    "    num_layers=configs.num_layers,\n",
    "    model=configs.model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73db7c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test GPT Model\n",
    "model.load_state_dict(torch.load(\"gpt.pt\"))\n",
    "\n",
    "def text_generator(sentence: str, length: int):\n",
    "    # sentence : 입력 문장\n",
    "    # length : 몇 글자를 더 이어 쓸것인지\n",
    "    inputs = tokenizer.encode(sentence)\n",
    "    inputs = torch.Tensor(inputs).unsqueeze(0).long().cuda()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(length):\n",
    "            # 문장 뒤에 아무 글자나 붙여서 다음 글자까지 예측하도록 함.\n",
    "            blank = torch.Tensor([[5]]).cuda()\n",
    "            inputs = torch.cat((inputs, blank), dim=1).long()\n",
    "            input_lengths = torch.Tensor(inputs.size(1)).long().cuda()\n",
    "            logits, preds = model.forward(inputs, input_lengths)\n",
    "            \n",
    "            # 앞의 글자들은 바꿀 것이 아니기 때문에 예측한 맨 마지막 글자만 뒤에 추가한다!\n",
    "            inputs[0][-1] = preds[0][-1]\n",
    "            print(tokenizer.decode(inputs))\n",
    "    return tokenizer.decode(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cab4f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generator(\"이건 근의 공식을\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a1d2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test BERT Model\n",
    "\n",
    "model.load_state_dict(torch.load(\"bert.pt\"))\n",
    "\n",
    "def text_corrector(sentence: str, mask_num: int):\n",
    "    # sentence : 입력 문장\n",
    "    # mask_num : masking 할 문자 수\n",
    "    mask_indexes = random.sample(range(len(sentence)), mask_num)\n",
    "\n",
    "    #inputs = [tokenizer.sos_token] + tokenizer.encode(sample) + [tokenizer.eos_token]\n",
    "    inputs = tokenizer.encode(sample)\n",
    "    for idx in mask_indexes:\n",
    "        inputs[idx] = 2000\n",
    "\n",
    "    input_length = [len(inputs)]\n",
    "    \n",
    "    inputs = torch.Tensor(inputs).unsqueeze(0).int()\n",
    "    inputs = inputs.cuda()\n",
    "\n",
    "    logits, preds = model(inputs, input_length)\n",
    "\n",
    "    for idx in mask_indexes:\n",
    "        # <sos> 빼고\n",
    "        inputs[0][idx] = preds[0][idx]\n",
    "\n",
    "    return tokenizer.decode(inputs[0][1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69f118b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_corrector(\"이렇게 좋은 날씨에 사무실에서 뭐하는 거람\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
