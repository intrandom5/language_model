{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30b0afd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Configs:\n",
    "    def __init__(self):\n",
    "        self.manifest_file = \"total_am.txt\"\n",
    "        self.labels_path = \"aihub_labels.csv\"\n",
    "        self.train_ratio = 0.8\n",
    "        self.num_workers = 4\n",
    "        self.batch_size = 64\n",
    "        self.sample_mode = 'random' #'smart'\n",
    "        self.teacher_forcing_ratio = 0.0\n",
    "        \n",
    "        self.num_classes = 2001\n",
    "        self.d_model = 512\n",
    "        self.d_ff = 2048\n",
    "        self.num_heads = 4\n",
    "        self.num_layers = 3\n",
    "        self.model_name = \"BERT\"\n",
    "        \n",
    "configs = Configs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3067f5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Tokenizer import Tokenizer\n",
    "from data_module import DataModule\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(label_file=configs.labels_path)\n",
    "data_module = DataModule(configs, tokenizer)\n",
    "train_dataloader = data_module.get_dl(\"train\")\n",
    "valid_dataloader = data_module.get_dl(\"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac4ce0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model import Transformer_LM\n",
    "\n",
    "model = Transformer_LM(\n",
    "    num_classes=configs.num_classes,\n",
    "    d_model=configs.d_model,\n",
    "    d_ff=configs.d_ff,\n",
    "    num_heads=configs.num_heads,\n",
    "    num_layers=configs.num_layers,\n",
    "    model=configs.model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "582d2964",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbcf1ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from criterion import CrossEntropyLoss, Perplexity\n",
    "from torch.optim import Adam\n",
    "\n",
    "Loss = CrossEntropyLoss(tokenizer)\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08ee8a67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "\n",
    "\n",
    "writer = SummaryWriter('runs/bert')\n",
    "\n",
    "for iteration, (inputs, seq_lengths, targets) in enumerate(train_dataloader):\n",
    "    inputs = inputs.cuda()\n",
    "    targets = targets.cuda()\n",
    "    optimizer.zero_grad()\n",
    "    logits, preds = model(inputs, seq_lengths)\n",
    "    loss = Loss(logits, targets)\n",
    "    perplexity = torch.exp(loss)\n",
    "    writer.add_scalar(\"train_loss\", loss, iteration)\n",
    "    writer.add_scalar(\"train_perplexity\", perplexity, iteration)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if iteration % 1000 == 0 and iteration != 0:\n",
    "        VAL_LOSS = 0\n",
    "        val_iter = 0\n",
    "        for i, (val_inputs, val_lengths, val_targets) in enumerate(valid_dataloader):\n",
    "            if i > 100:\n",
    "                break\n",
    "            val_inputs = val_inputs.cuda()\n",
    "            val_targets = val_targets.cuda()\n",
    "            with torch.no_grad():\n",
    "                logits, preds = model(val_inputs, val_lengths)\n",
    "            val_loss = Loss(logits, val_targets)\n",
    "            VAL_LOSS += val_loss\n",
    "            val_iter += 1\n",
    "        validation_loss = VAL_LOSS/val_iter\n",
    "        validation_perplexity = torch.exp(validation_loss)\n",
    "        writer.add_scalar(\"validation_loss\", validation_loss, iteration)\n",
    "        writer.add_scalar(\"validation_perplexity\", validation_perplexity, iteration)\n",
    "            \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61bcacd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"bert.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f6ffa7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos>이 좋은 날씨<mask> 난 사무<mask>에 앉아서 <mask> 하는거람<eos>\n",
      "<sos>이 좋은 날씨에 난 사무진에 앉아서 안 하는거람<eos>\n"
     ]
    }
   ],
   "source": [
    "# Test Bert Model\n",
    "import random\n",
    "\n",
    "sample = \"이 좋은 날씨에 난 사무실에 앉아서 뭘 하는거람\"\n",
    "\n",
    "tokenizer.idx2char[2000] = \"<mask>\"\n",
    "\n",
    "mask_indexes = random.sample(range(len(sample)), 3)\n",
    "\n",
    "#inputs = tokenizer.encode(sample)\n",
    "inputs = [tokenizer.sos_token] + tokenizer.encode(sample) + [tokenizer.eos_token]\n",
    "for idx in mask_indexes:\n",
    "    inputs[idx] = 2000\n",
    "    \n",
    "print(tokenizer.decode(inputs))\n",
    "\n",
    "input_length = [len(inputs)]\n",
    "\n",
    "inputs = torch.Tensor(inputs).unsqueeze(0).int()\n",
    "\n",
    "inputs = inputs.cuda()\n",
    "\n",
    "logits, preds = model(inputs, input_length)\n",
    "\n",
    "for idx in mask_indexes:\n",
    "    # <sos> 빼고\n",
    "    inputs[0][idx] = preds[0][idx]\n",
    "    \n",
    "result = tokenizer.decode(inputs[0])\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
